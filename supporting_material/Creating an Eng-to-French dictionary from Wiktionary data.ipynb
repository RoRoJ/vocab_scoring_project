{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Eng-to-French dictionary from Wiktionary data\n",
    "\n",
    "This notebook shows how the en-fr-wiktionary.dict file (downloaded from https://en.wiktionary.org/wiki/User:Matthias_Buchmeier#English-French) was wrangled into a pandas dataframe and used with the Levenshtein module to create a dictionary object (saved with the pickle module) for use by the L1SimilarityFeature class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import Levenshtein\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-file\n",
    "def save_obj(obj, name ):\n",
    "    with open(r'C:/Users/rowena/Documents/MSC/Project/obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(r'C:/Users/rowena/Documents/MSC/Project/obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import french_dict and whip it into shape\n",
    "with open('/Users/rowena/Documents/MSC/Project/FrenchCorpus/dictionary/en-fr-enwiktionary.dict', 'r', encoding='utf-8') as myfile:\n",
    "    french_dict = myfile.read().splitlines()\n",
    "\n",
    "#trim the beginning of the file\n",
    "french_dict=[item for item in french_dict[23:]]\n",
    "\n",
    "#create a list so that every list item is a pair of tuples, first tuple being english entry, second tuple being its french trans\n",
    "frenchdict_list=[]\n",
    "for i in range(0, len(french_dict), 2):\n",
    "    if i+2<=len(french_dict):\n",
    "        frenchdict_list.append((french_dict[i], french_dict[i + 1]))\n",
    "\n",
    "#use a dataframe to finish cleaning up the dictionary\n",
    "french_frame = pd.DataFrame(frenchdict_list) #make df from eng-->fr dict\n",
    "french_frame.columns=['eng', 'fr'] #rename the two columns\n",
    "french_frame['eng_tag']= \"\" #add col to hold <v> <n> etc\n",
    "french_frame['eng_det']=\"\" #add col to hold SEE: etc\n",
    "french_frame['fr_tosee']=\"\" #add col to hold the single word we should SEE for this entry\n",
    "french_frame = french_frame[['eng', 'eng_tag', 'eng_det', 'fr','fr_tosee']] #reorder the cols\n",
    "french_frame = french_frame.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) #strip leading/trailing whitespace\n",
    "        \n",
    "#extract the <v> <article> etc tag and put in separate column\n",
    "for index, row in french_frame.iterrows():\n",
    "    tagstart=row['eng'].find('<')\n",
    "    tagend=row['eng'].find('>')+1\n",
    "    row['eng_det']=row['eng'][tagend:]\n",
    "    row[\"eng_tag\"] = row['eng'][tagstart:tagend]\n",
    "    row[\"eng\"] = row['eng'][:tagstart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some entries' french translation field actually contains an instruction to 'SEE' (another entry). We deal with that here\n",
    "#by copying over such translations into the correct field.\n",
    "\n",
    "#make a dictionary to perform 'SEE' mappings (initial loop)\n",
    "french_frame_engfr=french_frame[['eng', 'fr']]\n",
    "french_frame_engfr = french_frame_engfr.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) #strip leading/trailing whitespace\n",
    "mydict = french_frame_engfr.set_index('eng').to_dict()\n",
    "mydict = mydict['fr']\n",
    "\n",
    "#copy over mappings (initial loop)\n",
    "for index, row in french_frame.iterrows():\n",
    "    if 'SEE:' in row['eng_det']:\n",
    "        seepos = row['eng_det'].find('SEE:')+6\n",
    "        row['fr_tosee']=row['eng_det'][seepos:-1]\n",
    "        \n",
    "french_frame['fr_seen'] = french_frame['fr_tosee'].map(mydict)\n",
    "\n",
    "for index, row in french_frame.iterrows():\n",
    "    if 'SEE:' in row['eng_det']:\n",
    "        row['fr'] = row['fr_seen']\n",
    "    row['fr'] = re.sub('<.*?>', '', row['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after copying over the definitions from the SEE references, there are still 343 rows with blank translations\n",
    "blank_fr=0\n",
    "for index, row in french_frame.iterrows():\n",
    "    if row['fr']=='':\n",
    "        blank_fr+=1\n",
    "blank_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a dictionary to perform 'SEE' mappings (second loop)\n",
    "french_frame_engfr=french_frame[['eng', 'fr']]\n",
    "french_frame_engfr = french_frame_engfr.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) #strip leading/trailing whitespace\n",
    "mydict = french_frame_engfr.set_index('eng').to_dict()\n",
    "mydict = mydict['fr']\n",
    "\n",
    "french_frame['fr_seen'] = french_frame['fr_tosee'].map(mydict)\n",
    "\n",
    "#copy over mappings (second loop)\n",
    "for index, row in french_frame.iterrows():\n",
    "    if row['fr']=='':\n",
    "        row['fr'] = row['fr_seen']\n",
    "    ##deleted re row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after copying over the definitions from the second round SEE references, there are still 15 rows with blank translations\n",
    "blank_fr=0\n",
    "for index, row in french_frame.iterrows():\n",
    "    if row['fr']=='':\n",
    "        blank_fr+=1\n",
    "blank_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a dictionary to perform 'SEE' mappings (third loop)\n",
    "french_frame_engfr=french_frame[['eng', 'fr']]\n",
    "french_frame_engfr = french_frame_engfr.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) #strip leading/trailing whitespace\n",
    "mydict = french_frame_engfr.set_index('eng').to_dict()\n",
    "mydict = mydict['fr']\n",
    "\n",
    "french_frame['fr_seen'] = french_frame['fr_tosee'].map(mydict)\n",
    "\n",
    "#copy over mappings (third loop)\n",
    "for index, row in french_frame.iterrows():\n",
    "    if row['fr']=='':\n",
    "        row['fr'] = row['fr_seen']\n",
    "    row['fr'] = re.sub('<.*?>', '', str(row['fr'])).strip()\n",
    "    ##deleted re row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after copying over the definitions from the third round SEE references, there no blank definitions left\n",
    "blank_fr=0\n",
    "for index, row in french_frame.iterrows():\n",
    "    if row['fr']=='':\n",
    "        blank_fr+=1\n",
    "blank_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get rid of unwanted columns\n",
    "french_frame = french_frame.drop(columns=['fr_tosee', 'fr_seen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old value:  answer  [1, 2] répondre\n",
      "new value:  answer  répondre\n",
      "old value:  concentrate  [1,2] concentrer, [3] se concentrer\n",
      "new value:  concentrate  concentrer, se concentrer\n",
      "old value:  crack  [1,3] essai , [2] dégustation\n",
      "new value:  crack  [1,3] essai , [2] dégustation\n",
      "old value:  deracinate  [1, 2] déraciner\n",
      "new value:  deracinate  déraciner\n",
      "old value:  fur  [1, 3] pelage\n",
      "new value:  fur  pelage\n",
      "old value:  linear  [1,2] linéaire\n",
      "new value:  linear  linéaire\n",
      "old value:  Persian  [1,2] Persan\n",
      "new value:  Persian  Persan\n",
      "old value:  return  [1, 2] répondre\n",
      "new value:  return  [1, 2] répondre\n",
      "old value:  try  [1,3] essai , [2] dégustation\n",
      "new value:  try  essai, dégustation\n",
      "old value:  we  [1,2] nous [formal], on [informal]\n",
      "new value:  we   nous, on\n"
     ]
    }
   ],
   "source": [
    "#deal with some anomaly rows that use square brackets and commas oddly, noticed during testing\n",
    "pattern = re.compile(r'\\[[^)]*\\]')\n",
    "for index, row in french_frame.iterrows():\n",
    "    if str(row['fr']).startswith(\"[1,\"):\n",
    "        print('old value: ', row['eng'], row['fr'])\n",
    "        if str(row['eng']).startswith(\"answer\"):\n",
    "            row['fr']=re.sub(pattern, '', str(row['fr'])).strip()\n",
    "        if str(row['eng']).startswith(\"concentrate\"):\n",
    "            row['fr']='concentrer, se concentrer'\n",
    "        if str(row['eng']).startswith(\"deracinate\"):\n",
    "            row['fr']=re.sub(pattern, '', str(row['fr'])).strip()\n",
    "        if str(row['eng']).startswith(\"fur\"):\n",
    "            row['fr']=re.sub(pattern, '', str(row['fr'])).strip()\n",
    "        if str(row['eng']).startswith(\"linear\"):\n",
    "            row['fr']=re.sub(pattern, '', str(row['fr'])).strip()\n",
    "        if str(row['eng']).startswith(\"Persian\"):\n",
    "            row['fr']=re.sub(pattern, '', str(row['fr'])).strip()\n",
    "        if str(row['eng']).startswith(\"try\"):\n",
    "            row['fr']=\"essai, dégustation\"\n",
    "        if str(row['eng']).startswith(\"we\"):\n",
    "            row['fr']=\" nous, on\"\n",
    "        print('new value: ', row['eng'], row['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72827"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we observe the number of entries in the dictionary\n",
    "len(french_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows in dataframe is  72827\n",
      "fr_alt0 has 0  blank rows\n",
      "fr_alt1 has 56133  blank rows\n",
      "fr_alt2 has 68317  blank rows\n",
      "fr_alt3 has 71305  blank rows\n",
      "fr_alt4 has 72247  blank rows\n",
      "fr_alt5 has 72557  blank rows\n",
      "fr_alt6 has 72706  blank rows\n",
      "fr_alt7 has 72758  blank rows\n",
      "fr_alt8 has 72798  blank rows\n",
      "fr_alt9 has 72808  blank rows\n",
      "fr_alt10 has 72816  blank rows\n",
      "fr_alt11 has 72818  blank rows\n",
      "fr_alt12 has 72820  blank rows\n",
      "fr_alt13 has 72822  blank rows\n",
      "fr_alt14 has 72824  blank rows\n",
      "fr_alt15 has 72824  blank rows\n",
      "fr_alt16 has 72825  blank rows\n",
      "fr_alt17 has 72825  blank rows\n",
      "fr_alt18 has 72825  blank rows\n",
      "fr_alt19 has 72825  blank rows\n",
      "fr_alt20 has 72826  blank rows\n",
      "fr_alt21 has 72826  blank rows\n",
      "fr_alt22 has 72826  blank rows\n",
      "fr_alt23 has 72826  blank rows\n",
      "fr_alt24 has 72826  blank rows\n"
     ]
    }
   ],
   "source": [
    "#split rows containing multiple possible translations for their entry, so that each translation is in  separate column.\n",
    "#The maximum number of translations for an entry is 24\n",
    "french_frame_2 = french_frame.join(french_frame['fr'].str.split(',', expand=True).add_prefix('fr_alt'))\n",
    "print('total rows in dataframe is ', len(french_frame_2))\n",
    "for i in range(25):\n",
    "    name=str('fr_alt'+str(i))\n",
    "    print(name, 'has', french_frame_2[name].isnull().sum(), ' blank rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPROVEMENT! Some translations contain supplementary information in brackets that is not part of the translation.\n",
    "# Remove any text within brackets from any given definition\n",
    "pattern = re.compile(r'\\([^)]*\\)')\n",
    "pattern2 = re.compile(r'\\[[^)]*\\]')\n",
    "for index, row in french_frame_2.iterrows():\n",
    "    for i in range(25):\n",
    "        name=str('fr_alt'+str(i))\n",
    "        text= str(row[name])\n",
    "        row[name]=re.sub(pattern, '', text).strip()\n",
    "        text= str(row[name])\n",
    "        row[name]=re.sub(pattern2, '', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loops through the 24 possible translations of each row, and preserves that which has the lowest \n",
    "#Levenshtein distance from its english \n",
    "french_frame_2['final']=\"\"\n",
    "for index, row in french_frame_2.iterrows():\n",
    "    row['final']=(row['fr_alt0'].strip(), Levenshtein.ratio(row['eng'].strip(), str(row['fr_alt0'].strip())))\n",
    "    for i in range(25):\n",
    "        name=str('fr_alt'+str(i))\n",
    "        if row[name]!=\"None\":\n",
    "            currentcalc=(str(row[name]).strip(), Levenshtein.ratio(str(row['eng'].strip()), str(row[name]).strip()))\n",
    "            if row['final'][1]<currentcalc[1] :\n",
    "                row['final']=currentcalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#invert the Levenshtein score so that the least similar words have the highest score for the feature\n",
    "french_frame_2['final_inverted']=''\n",
    "for index, row in french_frame_2.iterrows():\n",
    "    row['final_inverted']=(row['final'][0], 1-row['final'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#turns the english entry for any MWE into tuples\n",
    "for index, row in french_frame_2.iterrows():\n",
    "    row['eng'] = row['eng'].strip()\n",
    "    if ' ' in row['eng']:\n",
    "        row['eng']=tuple(row['eng'].split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Dictionary Creation (no POS tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#creates a dictionary var from the frame. Where there are multiple entries for the same english word,\n",
    "#only the entry with the lowest(in fact highest as inverted) Levenshtein distance from its translation is kept\n",
    "blank_dict=[]\n",
    "\n",
    "for index, row in french_frame_2.iterrows():\n",
    "    if type(row['eng'])!=tuple:\n",
    "        row['eng'] = row['eng'].strip()\n",
    "    if row['eng'] not in [item[0] for item in blank_dict]:\n",
    "        blank_dict.append((row['eng'], row['final_inverted']))\n",
    "    elif dict(blank_dict)[row['eng']][1]>row['final_inverted'][1]:\n",
    "        blank_dict=[item for item in blank_dict if item[0] !=row['eng']]\n",
    "        blank_dict.append((row['eng'], row['final_inverted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blank_dict=dict(blank_dict)\n",
    "save_obj(blank_dict, 'french_dict_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Dictionary Creation (with POS tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a column which holds the eng + its p.o.s tag\n",
    "french_frame_2['eng_and_tag']=''\n",
    "for index, row in french_frame_2.iterrows():\n",
    "    if type(row['eng'])!=tuple:\n",
    "        row['eng'] = row['eng'].strip() \n",
    "    row['eng_and_tag'] = (row['eng'], row['eng_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#creates a dictionary var from the frame. Where there are multiple entries for the same english word + POS tag,\n",
    "#only the entry with the lowest(in fact highest as inverted) Levenshtein distance from its translation is kept\n",
    "blank_dict2=[]\n",
    "\n",
    "for index, row in french_frame_2.iterrows():\n",
    "    if row['eng_and_tag'] not in [item[0] for item in blank_dict2]:\n",
    "        blank_dict2.append((row['eng_and_tag'], row['final_inverted']))\n",
    "    elif dict(blank_dict2)[row['eng_and_tag']][1]>row['final_inverted'][1]:\n",
    "        blank_dict2=[item for item in blank_dict2 if item[0] !=row['eng_and_tag']]\n",
    "        blank_dict2.append((row['eng_and_tag'], row['final_inverted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blank_dict2=dict(blank_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_obj(blank_dict2, 'french_dict_pos')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
